{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72d6c44-05cf-4d79-823f-2e039493424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first import the needed library for Word2Vec\n",
    "import gensim as gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e488ad7b-0a09-4ef6-bcb7-e719c92d8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For your purpose, all that is needed to be done is to initialize the model\n",
    "#Make sure you downloaded the word2vec-sentences-of-reports.model that is within the shared google drive\n",
    "model = gn.models.Word2Vec.load(\"word2vec-sentences-of-reports.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "501bf2d1-3b88-4a73-ae3f-1e520283544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2844363   3.6138585  -4.3653884   1.785943   -2.798078    0.21794051\n",
      "  3.4894607  -2.6016705  -1.2786173  -1.5456183  -1.0040268  -0.2186051\n",
      " -0.440443   -1.4240683   0.34291667 -3.0680308   3.828211    0.55606306\n",
      " -3.3824818   0.42963615  2.7581573  -1.3097543   0.5300402  -0.21449126\n",
      "  2.127863    3.0138452  -2.4854774  -0.42702547 -0.69270676  0.15612762\n",
      "  0.06533768 -2.008005    2.4211895  -1.3227948   2.1351027   0.7325434\n",
      "  2.3970587   1.0454459  -2.6887546  -2.4090452   2.6659803   2.3102713\n",
      "  3.4763749  -3.4616902  -2.4590724  -1.3661119  -0.42705974  1.8944649\n",
      "  1.8925555   1.6877143  -0.1760985  -1.6926858   0.16086215  1.0964311\n",
      " -0.65680796  0.43158635 -1.3576443   0.6275136   2.2602932   2.0570621\n",
      " -2.0325558   2.4753394   0.35837436 -1.4036176   0.5565392   2.6922765\n",
      "  1.4171176   1.3534471  -0.8967528   0.93888706  2.9829557  -0.6633227\n",
      " -0.32758158  2.2570224  -3.4693978  -1.2205118   0.5826706  -0.77839744\n",
      "  2.3533342  -1.1254004  -3.559579    2.3722537  -4.4676404   1.7803899\n",
      " -1.0614172   1.3759668   2.9552498  -1.971331   -3.7226305  -1.7899851\n",
      "  0.5202795  -3.8440871   5.7930427  -4.1233144  -1.7804699  -2.1027844\n",
      "  0.25537094 -2.49046    -2.2650769  -2.334771  ]\n"
     ]
    }
   ],
   "source": [
    "#With model, every word should now be represented as a vector. The following just verifies its working\n",
    "#by printing out the vector of the word plt (that was added in through the training; info was left at bottom)\n",
    "print(model.wv[\"plt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda6eb62-3221-464b-905c-2fc15dfd4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT UNCOMMENT THE FOLLOWING\n",
    "#(IT HAS BEEN INCLUDED JUST FOR YOUR INFORMATION AS TO HOW YOU WOULD CREATE YOUR OWN MODEL IN THE FUTURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf421010-e283-4539-9bfa-a28cb3ab9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = gn.models.Word2Vec(\n",
    "    #window=10,\n",
    "    #min_count=2,\n",
    "    #workers=4\n",
    "#)\n",
    "\n",
    "#NOTE: preprocess = dbSentences.sentence.apply(gn.utils.simple_preprocess) \n",
    "#                  where dbSentences is just another data frame created from \n",
    "#                  the pickle file consisting of only the sentences without their sentiment or ACN values\n",
    "#                  What returns is each sentence being an array of the words within them. EX: The dog walks --> [The, dog, walks]\n",
    "\n",
    "\n",
    "#model.build_vocab(preprocess, progress_per=1000)\n",
    "#The process of build vocab is straight foward. We simply are expanding on top of Word2Vecs already pretrained vocabulary by passing our \n",
    "#preprocessed data frame into it, which word2vec allocates within the vector space randomly.\n",
    "\n",
    "\n",
    "#model.train(preprocess, total_examples=model.corpus_count,epochs=model.epochs)\n",
    "#now that the words are within the vector space, we have to make sure it is adjusted to be within the correct \"area\". Train allows us to pass our\n",
    "#entire data frame again but this time with context of other words and moves it towards the actual space it belongs to.\n",
    "#With \n",
    "\n",
    "#model.save(\"./word2vec-sentences-of-reports.model\")\n",
    "#We save these new words and the newly updated vectors as a model. This model then just needs to be initialized and these steps can be ommitted.\n",
    "#This is why it is commented out as it has already been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b92c909-b594-4a8b-9d04-5c55c78462cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pilot', 0.8708917498588562),\n",
       " ('pic', 0.6920456886291504),\n",
       " ('cfi', 0.6366532444953918),\n",
       " ('plts', 0.6031377911567688),\n",
       " ('pilots', 0.5991186499595642),\n",
       " ('instructor', 0.5806552171707153),\n",
       " ('sic', 0.5711166858673096),\n",
       " ('cfii', 0.5703719258308411),\n",
       " ('lupton', 0.5570476651191711),\n",
       " ('instr', 0.5553929209709167)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OKAY , hopefully that cleared things up. So now when you ask for similar words, since the vectors should have moved to the corresponding area\n",
    "#what is returned is the other words that are near by. Check it out\n",
    "model.wv.most_similar(\"plt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197a7ef8-4ff1-4120-95f6-3434ca2fc55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that the right value is the percentage of its similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d8be0-4c0d-474d-9efb-9a1418bc0146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
